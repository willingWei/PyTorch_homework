{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('.\\\\names\\\\*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('\\\\')[-1].split('.')[0]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Spanish', 'Abascal')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, [33, 4, 17, 1, 4, 17, 19], [4, 17, 1, 4, 17, 19, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.i2h = nn.Linear(category_size + name_size,hidden_size)\n",
    "      \n",
    "        # 隐含层内部的相互链接\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first = True)\n",
    "        \n",
    "        # 输出层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    " \n",
    "        # 从输入到隐含层的计算\n",
    "        x = self.i2h(torch.cat((category_variable,name_variable),2))\n",
    "        \n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        output, hidden = self.lstm(x, hidden)\n",
    "        output = output[:,-1,:]\n",
    "\n",
    "        # 全连接层\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    hidden = lstm.initHidden()\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_tensor = torch.zeros(1,1,n_categories)\n",
    "    category_tensor[0][0][category_input] = 1\n",
    "    category_variable = Variable(category_tensor)\n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        letter = line_input[t]\n",
    "        name_tensor = torch.zeros(1,1,n_letters)\n",
    "        name_tensor[0][0][letter] = 1\n",
    "        name_variable = Variable(name_tensor)\n",
    "        # 目标\n",
    "        y = Variable(torch.LongTensor([line_target[t]]))\n",
    "        # 传入模型\n",
    "        output, hidden = lstm(category_variable,name_variable, hidden)\n",
    "        # 累加损失\n",
    "        loss += criterion(output, y)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    loss = 1.0 * loss / len(line_input)\n",
    "    loss.backward(retain_variables = True)\n",
    "    optimizer.step()\n",
    "    # train_loss += loss\n",
    "    # 反向传播、更新梯度\n",
    "    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "num_epoch = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型\n",
    "lstm = LSTMNetwork(category_size = n_categories, name_size = n_letters, hidden_size = HIDDEN_SIZE, output_size = n_letters, num_layers = 1)\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "1.00000e-02 *\n",
       "  -4.9922\n",
       "[torch.FloatTensor of size 1x1x1]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(1,1,n_letters)\n",
    "b = torch.zeros(1,1,n_categories)\n",
    "b\n",
    "# b = torch.zeros(5)\n",
    "# a[1] = 1\n",
    "# a\n",
    "c = torch.cat((a,b),2)\n",
    "# c\n",
    "nn.Linear(n_letters+n_categories,1)(Variable(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwz\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\torch\\autograd\\__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n",
      "C:\\Users\\wwz\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\wwz\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：inf，训练进度：0.0%，（0m 2s）\n",
      "第0轮，训练损失：2.79，训练进度：4.98%，（1m 4s）\n",
      "第0轮，训练损失：2.66，训练进度：9.96%，（2m 2s）\n",
      "第0轮，训练损失：2.58，训练进度：14.94%，（2m 51s）\n",
      "第0轮，训练损失：2.53，训练进度：19.93%，（3m 40s）\n",
      "第0轮，训练损失：2.49，训练进度：24.91%，（4m 26s）\n",
      "第0轮，训练损失：2.46，训练进度：29.89%，（5m 14s）\n",
      "第1轮，训练损失：inf，训练进度：33.33%，（6m 11s）\n",
      "第1轮，训练损失：2.26，训练进度：38.31%，（7m 6s）\n",
      "第1轮，训练损失：2.24，训练进度：43.3%，（8m 4s）\n",
      "第1轮，训练损失：2.23，训练进度：48.28%，（8m 57s）\n",
      "第1轮，训练损失：2.22，训练进度：53.26%，（9m 42s）\n",
      "第1轮，训练损失：2.22，训练进度：58.24%，（10m 28s）\n",
      "第1轮，训练损失：2.21，训练进度：63.22%，（11m 16s）\n",
      "第2轮，训练损失：inf，训练进度：66.67%，（12m 0s）\n",
      "第2轮，训练损失：2.17，训练进度：71.65%，（12m 51s）\n",
      "第2轮，训练损失：2.16，训练进度：76.63%，（13m 48s）\n",
      "第2轮，训练损失：2.15，训练进度：81.61%，（14m 45s）\n",
      "第2轮，训练损失：2.15，训练进度：86.59%，（15m 40s）\n",
      "第2轮，训练损失：2.15，训练进度：91.57%，（16m 25s）\n",
      "第2轮，训练损失：2.14，训练进度：96.56%，（17m 11s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        loss = train_LSTM()\n",
    "        train_loss += loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, train_loss.data.numpy()[0] / i, float(training_process), time_since(start)))\n",
    "            records.append([train_loss.data.numpy()[0] / i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20f99846d68>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20f99845748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "    category_input = make_category_input(category)\n",
    "    category_tensor = torch.zeros(1,1,n_categories)\n",
    "    category_tensor[0][0][category_input] = 1\n",
    "    category_variable = Variable(category_tensor)\n",
    "    # 第一个字符\n",
    "    letter = make_chars_input(start_char)[0]\n",
    "    name_tensor = torch.zeros(1,1,n_letters)\n",
    "    name_tensor[0][0][letter] = 1\n",
    "    name_variable = Variable(name_tensor)\n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable,name_variable,hidden)\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            letter = make_chars_input(char)[0]\n",
    "            name_tensor = torch.zeros(1,1,n_letters)\n",
    "            name_tensor[0][0][letter] = 1\n",
    "            name_variable = Variable(name_tensor)\n",
    "            #name_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC'):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_chars_input(\"A\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raska\n",
      "Undan\n",
      "Sanin\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gorn\n",
      "Erder\n",
      "Rand\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saro\n",
      "Pares\n",
      "Astes\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chan\n",
      "Han\n",
      "Ing\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
